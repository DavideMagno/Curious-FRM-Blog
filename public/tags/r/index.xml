<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on The CuRious Financial Risk ManageR</title>
    <link>/tags/r.html</link>
    <description>Recent content in R on The CuRious Financial Risk ManageR</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Feb 2018 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Convert foreign currency valuations</title>
      <link>/2018/02/convert-foreign-currency-valuations.html</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/convert-foreign-currency-valuations.html</guid>
      <description>


&lt;p&gt;One of the most common problems when dealign with financial data is to have assets (or liabilities) denominated in a currency that is different from the domestic one.&lt;/p&gt;
&lt;p&gt;I propose a tidy solution to this problem that involves no use of for cycles.&lt;/p&gt;
&lt;p&gt;The principle of the solution is that converting each currency can be done in parallel using the &lt;strong&gt;map&lt;/strong&gt; function while the consolidation of the results will be done using the &lt;strong&gt;reduce&lt;/strong&gt; logic.&lt;/p&gt;
&lt;p&gt;I am a big fan of the tidyverse and therefore I will start loading the required packages&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)
library(stringr)
library(tibble)
library(magrittr)
library(dplyr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I suppose to have a very simple investment dataset made of two fields:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;a column with the currency of the investment (local currency being &lt;em&gt;EUR&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;a column with the market value of the investment in local currency&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Investments &amp;lt;- tibble(ccy = c(rep(&amp;quot;EUR&amp;quot;,2), rep(&amp;quot;JPY&amp;quot;,3), rep(&amp;quot;GBP&amp;quot;,3)),
                      local_MV = c(1.5e6,1.2e6,2e8,1.5e8,3e8,1e6,1.5e6,2e6)) %&amp;gt;% 
  mutate(local_MV = as.double(local_MV)) %&amp;gt;% 
  mutate(EUR_MV = local_MV)

Investments&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 3
##   ccy    local_MV    EUR_MV
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 EUR     1500000   1500000
## 2 EUR     1200000   1200000
## 3 JPY   200000000 200000000
## 4 JPY   150000000 150000000
## 5 JPY   300000000 300000000
## 6 GBP     1000000   1000000
## 7 GBP     1500000   1500000
## 8 GBP     2000000   2000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I then store in a list the current currency FX rates&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FX &amp;lt;- list(&amp;quot;JPY&amp;quot; = 130, &amp;quot;GBP&amp;quot; = 0.8)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first part of the algorithm consists in finding the rows of the Investments database which are subject to FX conversion for each of the currencies that are stored in the &lt;strong&gt;FX&lt;/strong&gt; list using the &lt;em&gt;stringr&lt;/em&gt; function &lt;em&gt;str_which&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This is the “parallel” part of the algorithm because it can be done currency by currency independently. We therefore use the &lt;em&gt;map&lt;/em&gt; function of the &lt;em&gt;purrr&lt;/em&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pos_ccy &amp;lt;- map(names(FX), ~str_which(Investments$ccy,.)) %&amp;gt;% 
  set_names(names(FX))

pos_ccy&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $JPY
## [1] 3 4 5
## 
## $GBP
## [1] 6 7 8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This list contains the row numbers for which there is an investment denominated in each of the currencies in the FX universe.
We then use this information together with the actual FX rate to convert the investments’ local market value. We now use the &lt;em&gt;map2&lt;/em&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;converted_MV &amp;lt;- map2(pos_ccy, FX ,~Investments$local_MV[.x]/.y)

converted_MV&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $JPY
## [1] 1538462 1153846 2307692
## 
## $GBP
## [1] 1250000 1875000 2500000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can notice that we now have a list made by two different vectors of converted market values. We need to consolidate those into the EUR_MV column in the Investments dataset.&lt;/p&gt;
&lt;p&gt;This is the second step of the algorithm that uses the &lt;em&gt;reduce&lt;/em&gt; function of &lt;em&gt;purrr&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Investments$EUR_MV[pos_ccy %&amp;gt;% reduce(c)] &amp;lt;- converted_MV %&amp;gt;% 
  reduce(c)

Investments&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 8 x 3
##   ccy    local_MV   EUR_MV
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 EUR     1500000 1500000 
## 2 EUR     1200000 1200000 
## 3 JPY   200000000 1538462.
## 4 JPY   150000000 1153846.
## 5 JPY   300000000 2307692.
## 6 GBP     1000000 1250000 
## 7 GBP     1500000 1875000 
## 8 GBP     2000000 2500000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function modifies rows of the EUR_MV field by reducing the lists from the map functions into vectors.&lt;/p&gt;
&lt;p&gt;We can notice that the EUR positions have not changed their market value.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Generate scenarios correlated to existing ones</title>
      <link>/2018/01/generate-scenarios-correlated-to-existing-ones.html</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/generate-scenarios-correlated-to-existing-ones.html</guid>
      <description>


&lt;p&gt;In quantitative finance we often look at simulations of some market risk factors like equity returns or interest rate changes.&lt;/p&gt;
&lt;p&gt;There are many third party companies who specialize in the historical calibration of such variables and provide simulations of future expected outcomes to the companies who require them.&lt;/p&gt;
&lt;p&gt;For example, let’s suppose that we receive the expected returns of the Google shares as per the following distribution&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This modelling is given by the third party and in theory we don&amp;#39;t know it
google &amp;lt;- rnorm(10000, mean = 0.01, sd = 0.20) %&amp;gt;% 
  tibble(google_returns = .)

ggplot(data = google, aes(x = google_returns)) + 
  geom_density() +
  scale_x_continuous(labels = percent) + 
  labs(title = &amp;quot;Google Shares&amp;quot;,
        subtitle = &amp;quot;One Year forward distribution&amp;quot;) +
  xlab(&amp;quot;One year forward return&amp;quot;) + 
  ylab(&amp;quot;Density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/22_01_2018_simulations_files/figure-html/Google-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We now want to simulate the distribution of another risk factor which is not provided by the third party but that is usefull for us. Let’s say it is the distribution of the Facebook shares which we imagine to:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;be distributed as a normal random variable&lt;/li&gt;
&lt;li&gt;have a 5% expected return and&lt;/li&gt;
&lt;li&gt;being quite volatile (30% annual volatility)&lt;/li&gt;
&lt;li&gt;have the same number of points as the simulations provided by the third party (10000 points)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We model therefore the distribution as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This modelling is our internal one and we can therefore control it
fb &amp;lt;- rnorm(10000, mean = 0.05, sd = 0.30) %&amp;gt;% 
  tibble(fb_returns = .)

ggplot(data = fb, aes(x = fb_returns)) + 
  geom_density() +
  scale_x_continuous(labels = percent) + 
  labs(title = &amp;quot;Facebook Shares&amp;quot;,
        subtitle = &amp;quot;One Year forward distribution&amp;quot;) +
  xlab(&amp;quot;One year forward return&amp;quot;) + 
  ylab(&amp;quot;Density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/22_01_2018_simulations_files/figure-html/Facebook-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s now look at the correlation between the two variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Returns &amp;lt;- google %&amp;gt;% 
  cbind(fb) %&amp;gt;% 
  as.tibble()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `as.tibble()` is deprecated, use `as_tibble()` (but mind the new semantics).
## This warning is displayed once per session.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(Returns$fb_returns, Returns$google_returns)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.006146476&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/22_01_2018_simulations_files/figure-html/Correlation_graph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can notice that performing the simple simulation doesn’t allow us to impose a correlation structure with the data provided by the third party provider.&lt;/p&gt;
&lt;p&gt;How can we generate a random variable with a defined correlation to an existing one?
A very elegant solution was provided by user &lt;strong&gt;whuber&lt;/strong&gt; at the following link &lt;a href=&#34;https://stats.stackexchange.com/a/313138&#34; class=&#34;uri&#34;&gt;https://stats.stackexchange.com/a/313138&lt;/a&gt; and by using the following function&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;complement &amp;lt;- function(y, rho, x) {
  if (missing(x)) x &amp;lt;- rnorm(length(y)) # Optional: supply a default if `x` is not given
  y.perp &amp;lt;- residuals(lm(x ~ y))
  rho * sd(y.perp) * y + y.perp * sd(y) * sqrt(1 - rho^2)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this function &lt;em&gt;x&lt;/em&gt; is our Facebook uncorrelated scenario , &lt;em&gt;rho&lt;/em&gt; is the correlation level and &lt;em&gt;y&lt;/em&gt; is the Google scenario as provided by the third party.&lt;/p&gt;
&lt;p&gt;We apply this function imposing an 80% correlation&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Returns %&amp;lt;&amp;gt;%  
  mutate(fb_correlated = complement(.$google_returns,0.8, .$fb_returns))

cor(Returns$google_returns, Returns$fb_correlated)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/22_01_2018_simulations_files/figure-html/Add_Correlation_Graph-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is just one last thing to do: compare the distributions of the two Facebook simulations&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Returns %&amp;gt;% 
  select(contains(&amp;quot;fb&amp;quot;)) %&amp;gt;% 
  gather(simulation_type, simulation_value) %&amp;gt;% 
  ggplot(aes(x = simulation_value, colour = simulation_type)) +
  geom_density() +
  scale_x_continuous(labels = percent) + 
  labs(title = &amp;quot;Facebook Shares&amp;#39; simulations&amp;quot;) +
  xlab(&amp;quot;One year forward return&amp;quot;) + 
  ylab(&amp;quot;Density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/22_01_2018_simulations_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can notice that the marginal distribution of the correlated scenario is much different from the original one.&lt;/p&gt;
&lt;p&gt;There is therefore one additional step before we finish: we need to rescale the marginal distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Rescaled_fb_correlated &amp;lt;- Returns %&amp;gt;%
  select(contains(&amp;quot;correlated&amp;quot;)) %&amp;gt;%
  scale() %&amp;gt;% 
  multiply_by(0.3) %&amp;gt;% 
  add(0.05)

Returns %&amp;lt;&amp;gt;% 
  mutate(fb_correlated_scaled = Rescaled_fb_correlated)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now check that the the marginals are comparable and that the correlation structure is still at the desired level&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Returns %&amp;gt;% 
  select(contains(&amp;quot;fb&amp;quot;)) %&amp;gt;% 
  gather(simulation_type, simulation_value) %&amp;gt;% 
  ggplot(aes(x = simulation_value, colour = simulation_type)) +
  geom_density() +
  scale_x_continuous(labels = percent) + 
  labs(title = &amp;quot;Facebook Shares&amp;#39; simulations&amp;quot;) +
  xlab(&amp;quot;One year forward return&amp;quot;) + 
  ylab(&amp;quot;Density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;../../post/22_01_2018_simulations_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(Returns$google_returns, Returns$fb_correlated)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new Facebook scenario is now both correlated and in line with the density we want.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
