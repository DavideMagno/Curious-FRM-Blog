<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>The CuRious Financial Risk ManageR</title>
    <link>/</link>
    <description>Recent content on The CuRious Financial Risk ManageR</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 Feb 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>US Federal Spending Analysis</title>
      <link>/2019/02/us-federal-spending-analysis/</link>
      <pubDate>Mon, 11 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/02/us-federal-spending-analysis/</guid>
      <description>This week&amp;#39;s #TidyTuesday is about federal spending. I was interested in understanding if spending had shifted towards clean energy sub-agencies in the last 20 years. Spoiler alert: unfortunately no! üò∞#Rstats #tidyverse cc @thomas_mock @R4DScommunity pic.twitter.com/AbQzheSagU
&amp;mdash; Davide Magno (@DavideMagno) February 12, 2019  </description>
    </item>
    
    <item>
      <title>Geospatial Analysis on Housing Price Index</title>
      <link>/2019/02/geospatial-analysis-on-housing-price-index/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/02/geospatial-analysis-on-housing-price-index/</guid>
      <description>Here&amp;#39;s my #TidyTuesday submission.I studied the total increase in the housing index for each US State compared to the US federal index. No surprise in California house price has increased much more than the rest of US.The #mapdata library was üëçüèº@thomas_mock @R4DScommunity #rstats pic.twitter.com/sYI1zKhIpC
&amp;mdash; Davide Magno (@DavideMagno) February 10, 2019  </description>
    </item>
    
    <item>
      <title>My First #TidyTuesday Submission</title>
      <link>/2019/02/my-first-tidytuesday-submission/</link>
      <pubDate>Sun, 03 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/02/my-first-tidytuesday-submission/</guid>
      <description>Finally my first #TidyTuesday submission! üéäüéâI am starting from week 1 2019 but I will catch up soonüòâWhen do people submit their visualisations?Mostly on Tuesday and Wednesday afternoon, but also on Monday before the new set is released #rstats #ggplot @rstats4ds @thomas_mock pic.twitter.com/pKZAyL8vp1
&amp;mdash; Davide Magno (@DavideMagno) February 3, 2019  </description>
    </item>
    
    <item>
      <title>Convert foreign currency valuations</title>
      <link>/2018/02/convert-foreign-currency-valuations/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/02/convert-foreign-currency-valuations/</guid>
      <description>One of the most common problems when dealign with financial data is to have assets (or liabilities) denominated in a currency that is different from the domestic one.
I propose a tidy solution to this problem that involves no use of for cycles.
The principle of the solution is that converting each currency can be done in parallel using the map function while the consolidation of the results will be done using the reduce logic.</description>
    </item>
    
    <item>
      <title>Generate scenarios correlated to existing ones</title>
      <link>/2018/01/generate-scenarios-correlated-to-existing-ones/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/01/generate-scenarios-correlated-to-existing-ones/</guid>
      <description>In quantitative finance we often look at simulations of some market risk factors like equity returns or interest rate changes.
There are many third party companies who specialize in the historical calibration of such variables and provide simulations of future expected outcomes to the companies who require them.
For example, let‚Äôs suppose that we receive the expected returns of the Google shares as per the following distribution
# This modelling is given by the third party and in theory we don&amp;#39;t know it google &amp;lt;- rnorm(10000, mean = 0.</description>
    </item>
    
  </channel>
</rss>